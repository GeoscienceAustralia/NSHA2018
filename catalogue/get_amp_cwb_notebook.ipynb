{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#!/opt/antelope/5.4/bin/python\n",
    "import numpy as np\n",
    "from obspy.core import utcdatetime\n",
    "#from obspy.neic.client import Client\n",
    "from obspy.clients.neic.client import Client\n",
    "from obspy.io.xseed import Parser\n",
    "#from obspy.core.util import gps2DistAzimuth\n",
    "from obspy.geodetics import gps2dist_azimuth as gps2DistAzimuth\n",
    "#from obspy.taup import TauPyModel\n",
    "from obspy.signal import invsim as inv\n",
    "from obspy.io.xseed.utils import SEEDParserException\n",
    "# plot all traces into one pdf file\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "# we will use dataless seed from IRIS to get station information\n",
    "parser = Parser(\"../../AU.dataless\")\n",
    "# travel-time model will be iasp91 but could be any\n",
    "#model = TauPyModel(model=\"iasp91\")\n",
    "from obspy.taup.taup import getTravelTimes\n",
    "r_earth = 6371\n",
    "def sind(x): return np.sin(x / 180. * np.pi)\n",
    "def cosd(x): return np.cos(x / 180. * np.pi)\n",
    "def tand(x): return np.tan(x / 180. * np.pi)\n",
    "def arcsind(x): return np.arcsin(x) / np.pi * 180\n",
    "def arccosd(x): return np.arccos(x) / np.pi * 180\n",
    "def arctand(x): return np.arctan(x) / np.pi * 180\n",
    "def gps2DistDegree(lat1, lon1, lat2, lon2):\n",
    "    return arccosd(sind(lat1) * sind(lat2) +\n",
    "                   cosd(lat1) * cosd(lat2) * cosd(lon1 - lon2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here we define how we measure peak to peak amplitude and period\n",
    "def max_p2t(data, delta):\n",
    "     \"\"\"\n",
    "     Function to find the maximum peak-to-trough amplitude and period of this \\\n",
    "     amplitude.\n",
    "\n",
    "     :type data: ndarray\n",
    "     :param data: waveform trace to find the peak-to-trough in.\n",
    "     :type delta: float\n",
    "     :param delta: Sampling interval in seconds\n",
    "\n",
    "     :returns: tuple of (amplitude, period, time) with amplitude in the same \\\n",
    "         scale as given in the input data, and period in seconds, and time in \\\n",
    "         seconds from the start of the data window.\n",
    "     \"\"\"\n",
    "     turning_points = []  # A list of tuples of (amplitude, sample)\n",
    "     for i in range(1, len(data) - 1):\n",
    "         if (data[i] < data[i-1] and data[i] < data[i+1]) or\\\n",
    "            (data[i] > data[i-1] and data[i] > data[i+1]):\n",
    "             turning_points.append((data[i], i))\n",
    "     if len(turning_points) >= 1:\n",
    "         amplitudes = np.empty([len(turning_points)-1],)\n",
    "         half_periods = np.empty([len(turning_points)-1],)\n",
    "     else:\n",
    "         print('Turning points has length: '+str(len(turning_points)) +\n",
    "               ' data have length: '+str(len(data)))\n",
    "         return (0.0, 0.0, 0.0)\n",
    "     for i in range(1, len(turning_points)):\n",
    "         half_periods[i-1] = (delta * (turning_points[i][1] -\n",
    "                                       turning_points[i-1][1]))\n",
    "         amplitudes[i-1] = np.abs(turning_points[i][0]-turning_points[i-1][0])\n",
    "     amplitude = np.max(amplitudes)\n",
    "     period = 2 * half_periods[np.argmax(amplitudes)]\n",
    "\n",
    "     return (amplitude, period, delta*turning_points[np.argmax(amplitudes)][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the cwb port\n",
    "client=Client(host='10.7.161.60',port=2061,debug=False)\n",
    "eq=[]\n",
    "# here we read all events line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USGS,tele,None,Preferred,2010,4,20,0,17,8,AWST,8,121.653,30.53,10,N,Mb,5.2,,13.3,,H,,18,0.87,,162,,5.531,,\"NNE of Kalgoorlie, WA\",Mb 5.2 USGS\n",
      "sample rate 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/users/u61092/unix/.local/lib/python2.7/site-packages/ipykernel/__main__.py:67: ObsPyDeprecationWarning: 'getCoordinates' has been renamed to 'get_coordinates'. Use that instead.\n",
      "/nas/users/u61092/unix/.local/lib/python2.7/site-packages/ipykernel/__main__.py:69: ObsPyDeprecationWarning: The getTravelTimes() function is deprecated. Please use the obspy.taup.TauPyModel class directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARMA BHE 1.0 691007.289044 None\n",
      "sample rate 40.0\n",
      "ARMA BHN 1.0 691007.289044 None\n",
      "sample rate 40.0\n",
      "ARMA BHZ 1.0 691007.289044 None\n",
      "sample rate 40.0\n",
      "AS31 BHE 1.0 691007.289044 None\n",
      "sample rate 40.0\n",
      "AS31 BHN 1.0 691007.289044 None\n",
      "sample rate 40.0\n",
      "AS31 BHZ 1.0 691007.289044 None\n",
      "sample rate 40.0\n",
      "BBOO BHE 1.0 691007.289044 None\n",
      "sample rate 40.0\n",
      "BBOO BHN 1.0 691007.289044 None\n",
      "sample rate 40.0\n",
      "BBOO BHZ 1.0 691007.289044 None\n",
      "sample rate 40.0\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../eq2.txt\",'r') as cat:\n",
    "    for line in cat:\n",
    "        eq=line.split(',')\n",
    "        yr=int(eq[4])\n",
    "        mon=int(eq[5])\n",
    "        day=int(eq[6])\n",
    "        hr=int(eq[7])\n",
    "        mn=int(eq[8])\n",
    "        sec=float(eq[9])\n",
    "        code=eq[10]\n",
    "        corr=float(eq[11])\n",
    "        lon=float(eq[12])\n",
    "        lat=float(eq[13])\n",
    "        dep=float(eq[14])\n",
    "\n",
    "        start_time=utcdatetime.UTCDateTime(yr,mon,day,hr,mn,int(sec),int((sec-int(sec))*100000))\n",
    "#        ''' correct the time if not UTC '''\n",
    "# Is this really needed??? Looks like may already be converted??\n",
    "#        if code==\"AEST\" :\n",
    "#            start_time-=36000\n",
    "#        if code==\"WITA\" or code==\"AWST\":\n",
    "#            start_time-=28800\n",
    "\n",
    "\n",
    "        ''' the time window to request the data will be 20 minutes, check maximum travel time and increase this value accordingly '''\n",
    "        end_time=start_time+960 # 16 minutes\n",
    "        ''' get all waveform data available, use wildcards to reduce the data volume and speedup the process,\n",
    "        unfortunately we need to request few times for every number of characters that forms the station name '''\n",
    "        st_3 = client.get_waveforms(\"AU\", \"???\", \"\", \"[BH]??\", start_time,end_time)\n",
    "        st_4 = client.get_waveforms(\"AU\", \"????\", \"\", \"[BH]??\", start_time,end_time)\n",
    "        if len(st_4) > 0:\n",
    "            st=st_3+st_4\n",
    "        else:\n",
    "            st=st_3\n",
    "\n",
    "        # Cleanup duplicate traces returned by server\n",
    " #       st.merge(-1) #-1 method only merges overlapping or adjacent traces with same i            \n",
    "        # Now sort the streams by station and channel\n",
    "        st.sort()\n",
    "        # Cleanup duplicate traces returned by server\n",
    "        st.merge(1, fill_value=None) #1 method only merges overlapping or adjacent traces with same id\n",
    "        # Now sort the streams by station and channel\n",
    "        st.sort()\n",
    "        \n",
    "        # Filter the stream - should it be done here on by trace???\n",
    "  #      st.filter(bandpass, freqmin=0.5, freqmax=10., )\n",
    "        # PDF file to plot all traces for this event\n",
    "        figpdf = PdfPages('test.pdf')\n",
    "\n",
    "        ''' first we will print the record of the earthquake as in catalogue '''\n",
    "        print line\n",
    "        \n",
    "        counter = 0 # For debugging only\n",
    "        for tr in st:\n",
    "            counter +=1\n",
    "            ''' get station ID'''\n",
    "            seedid=tr.get_id()\n",
    "#            numobs = tr.count()\n",
    "#            print 'count', numobs\n",
    "#            print 'seedid', seedid\n",
    "            print 'sample rate', tr.stats.sampling_rate\n",
    "            sample_rate = tr.stats.sampling_rate\n",
    "            # Filter the trace\n",
    "            tr.filter('bandpass', freqmin=0.5, freqmax=10., corners=6)#, df=sample_rate)\n",
    "            try:\n",
    "                ''' get station coordinates from dataless seed '''\n",
    "                tr.stats.coordinates = parser.getCoordinates(seedid,start_time)\n",
    "                tr.stats.distance =gps2DistDegree(tr.stats.coordinates.latitude,tr.stats.coordinates.longitude,lat,lon)\n",
    "                travel_times=getTravelTimes(tr.stats.distance,dep,model=\"iasp91\")\n",
    "                try:\n",
    "                   arrivals= (item for item in travel_times if item[\"phase_name\"]=='S' or item[\"phase_name\"]=='Sn').next()\n",
    "                except StopIteration:\n",
    "                   print \"WARNING: reference station \",tr.stats['station'],\" does not have S or Sn phases\"\n",
    "                figure = tr.plot(handle=True)\n",
    "                try:\n",
    "                    figpdf.savefig(figure)\n",
    "                    figure.close()\n",
    "                except:\n",
    "                    pass\n",
    "               # figpdf.close()\n",
    "#                  print travel_times\n",
    "                ''' lets select 20 seconds window from S-wave p2p measurements '''\n",
    "#               print start_time+arrivals['time'],start_time+arrivals['time']+20,end_time\n",
    " #               wave=tr.slice(start_time+arrivals['time'],start_time+arrivals['time']+20)\n",
    " #               if len(wave.data)>0:\n",
    " #                  amplitude,period,delay=max_p2t(wave.data,wave.stats.delta)\n",
    " #               else:\n",
    " #                   amplitude,period,delay = None,None,None\n",
    " #               if amplitude > 0. and period > 0. :\n",
    "                paz=parser.get_paz(seedid,start_time)\n",
    "                ''' calib is already applied therefore we set sensitivity to 1 '''\n",
    "                paz['sensitivity']=1.\n",
    "                # Define Wood Anderson paz based on Uhrhammer 1990 sensitivity of 2080\n",
    "                # rather than theoretical 2800 as used by obpy\n",
    "                # wa_amp=inv.estimateWoodAndersonAmplitude(paz,amplitude,period)\n",
    "                paz_wa = {'sensitivity': 2080, 'zeros': [0j], 'gain': 1,\n",
    "                          'poles': [-6.2832 - 4.7124j, -6.2832 + 4.7124j]}\n",
    "                # Now convert to WA spectra\n",
    "                wa_tr = tr.simulate(paz_remove=paz, paz_simulate=paz_wa)\n",
    "                # Plot WA record\n",
    "                figure = wa_tr.plot(handle=True)\n",
    "                try:\n",
    "                    figpdf.savefig(figure)\n",
    "                    figure.close()\n",
    "                except:\n",
    "                    pass\n",
    "                # Calculate WA amplitudes and periods\n",
    "                wave=wa_tr.slice(start_time+arrivals['time'],start_time+arrivals['time']+20)\n",
    "                if len(wave.data)>0:\n",
    "                    wa_amp,period,delay=max_p2t(wave.data,wave.stats.delta)\n",
    "                else:\n",
    "                    amplitude,period,delay = None,None,None\n",
    "                ''' now we print every station-component measurement '''\n",
    "                print tr.stats['station'],tr.stats['channel'],tr.stats['calib'],wa_amp,period\n",
    "                #else:\n",
    "                #    print tr.stats['station'],tr.stats['channel'],tr.stats['calib'],amplitude,period\n",
    "            except (SEEDParserException,AssertionError):\n",
    "                print  tr.stats['station'],tr.stats['channel'],'-1,-1,-1'\n",
    "            if counter > 10:\n",
    "                break\n",
    "    figpdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
