{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import local_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/opt/anaconda-2.3.0/bin/python2\n",
    "\"\"\"#!/opt/antelope/5.4/bin/python\"\"\"\n",
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "from obspy.core import utcdatetime, event\n",
    "from obspy.core.event import Catalog, Event, Magnitude, Origin, StationMagnitude\n",
    "#from obspy.neic.client import Client\n",
    "from obspy.clients.neic.client import Client\n",
    "from obspy.io.xseed import Parser\n",
    "#from obspy.core.util import gps2DistAzimuth\n",
    "from obspy.geodetics import gps2dist_azimuth as gps2DistAzimuth\n",
    "#from obspy.taup import TauPyModel\n",
    "from obspy.signal import invsim as inv\n",
    "from obspy.io.xseed.utils import SEEDParserException\n",
    "# plot all traces into one pdf file\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import pyplot\n",
    "# we will use dataless seed from IRIS to get station information\n",
    "parser = Parser(\"../../AU.dataless\")\n",
    "# travel-time model will be iasp91 but could be any\n",
    "from obspy import taup\n",
    "vel_model = taup.TauPyModel(model=\"iasp91\")\n",
    "#from obspy.taup.TauPyModel import get_travel_times\n",
    "# local modules\n",
    "#import local_magnitude\n",
    "r_earth = 6371\n",
    "def sind(x): return np.sin(x / 180. * np.pi)\n",
    "def cosd(x): return np.cos(x / 180. * np.pi)\n",
    "def tand(x): return np.tan(x / 180. * np.pi)\n",
    "def arcsind(x): return np.arcsin(x) / np.pi * 180\n",
    "def arccosd(x): return np.arccos(x) / np.pi * 180\n",
    "def arctand(x): return np.arctan(x) / np.pi * 180\n",
    "def gps2DistDegree(lat1, lon1, lat2, lon2):\n",
    "    return arccosd(sind(lat1) * sind(lat2) +\n",
    "                   cosd(lat1) * cosd(lat2) * cosd(lon1 - lon2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here we define how we measure peak to peak amplitude and period\n",
    "def max_p2t(data, delta):\n",
    "     \"\"\"\n",
    "     Function to find the maximum peak-to-trough amplitude and period of this \\\n",
    "     amplitude.\n",
    "\n",
    "     :type data: ndarray\n",
    "     :param data: waveform trace to find the peak-to-trough in.\n",
    "     :type delta: float\n",
    "     :param delta: Sampling interval in seconds\n",
    "\n",
    "     :returns: tuple of (amplitude, period, time) with amplitude in the same \\\n",
    "         scale as given in the input data, and period in seconds, and time in \\\n",
    "         seconds from the start of the data window.\n",
    "     \"\"\"\n",
    "     turning_points = []  # A list of tuples of (amplitude, sample)\n",
    "     for i in range(1, len(data) - 1):\n",
    "         if (data[i] < data[i-1] and data[i] < data[i+1]) or\\\n",
    "            (data[i] > data[i-1] and data[i] > data[i+1]):\n",
    "             turning_points.append((data[i], i))\n",
    "     if len(turning_points) >= 1:\n",
    "         amplitudes = np.empty([len(turning_points)-1],)\n",
    "         half_periods = np.empty([len(turning_points)-1],)\n",
    "     else:\n",
    "         print('Turning points has length: '+str(len(turning_points)) +\n",
    "               ' data have length: '+str(len(data)))\n",
    "         return (0.0, 0.0, 0.0)\n",
    "     for i in range(1, len(turning_points)):\n",
    "         half_periods[i-1] = (delta * (turning_points[i][1] -\n",
    "                                       turning_points[i-1][1]))\n",
    "         amplitudes[i-1] = np.abs(turning_points[i][0]-turning_points[i-1][0])\n",
    "     amplitude = np.max(amplitudes)\n",
    "     period = 2 * half_periods[np.argmax(amplitudes)]\n",
    "\n",
    "     return (amplitude, period, delta*turning_points[np.argmax(amplitudes)][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the cwb port\n",
    "client=Client(host='10.7.161.60',port=2061,debug=False, nonice=True)\n",
    "eq=[]\n",
    "# here we read all events line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate catalogue object\n",
    "catalogue = Catalog()\n",
    "# Build Quakeml Event object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/users/u61092/unix/.local/lib/python2.7/site-packages/obspy/core/event/base.pyc:325: UserWarning: The resource identifier 'GG_cat_0' already exists and points to another object: 'Event(resource_id=ResourceIdentifier(id=\"GG_cat_0\"), creation_info=CreationInfo(agency_id='JG'))'.It will now point to the object referred to by the new resource identifier.\n",
      "  \u0000\u0000\u0000|\u0000\u0000j\u0000\u0000ï¿½\u0000\u0000S(\u0001\u0000\u0000\u0000N(\u0001\u0000\u0000\u0000t\u0013\u0000\u0000\u0000get_referred_object(\u0001\u0000\u0000\u0000R&\u0000\u0000\u0000(\u0000\u0000\u0000\u0000(\u0000\u0000\u0000\u0000sR\u0000\u0000\u0000/nas/users/u61092/unix/.local/lib/python2.7/site-packages/obspy/core/event/base.pyt\u0011\u0000\u0000\u0000getReferredObject\u0018\u0002\u0000\u0000s\u0002\u0000\u0000\u0000\u0000\u0003c\u0001\u0000\u0000\u0000\u0001\u0000\u0000\u0000\u0005\u0000\u0000\u0000C`\u0003\u0000s+\u0000\u0000\u0000y\u0012\u0000t\u0000\u0000j\u0001\u0000|\u0000\u0000j\u0002\u0000\u0019SWn\u0012\u0000\u0004t\u0003\u0000k\n",
      "/nas/users/u61092/unix/.local/lib/python2.7/site-packages/obspy/io/mseed/core.py:384: InternalMSEEDReadingWarning: readMSEEDBuffer(): Unknown error '9' in record starting at offset 1019904. The rest of the file will not be read.\n",
      "  warnings.warn(*_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEL,local,Mainshock,Preferred,2010,5,26,10,9,21.8,AEST,10,144.746,36.748,10,N,ML,3.2,,,,,,,,,,,,,\"Axedale, Vic\",ML 3.2 MEL\r\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/users/u61092/unix/.local/lib/python2.7/site-packages/ipykernel/__main__.py:81: ObsPyDeprecationWarning: 'getCoordinates' has been renamed to 'get_coordinates'. Use that instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARMA BHE 1.0 948.733861616 101983.540468 1.7 2.91470720669\n",
      "ARMA BHN 1.0 948.733861616 115577.421898 1.45 2.96905012454\n",
      "ARPS SHE 1.0 259.635348613 1137359.44083 0.45 2.82894469758\n",
      "ARPS SHN 1.0 259.635348613 1178937.97354 0.3 2.84453791721\n",
      "AS31 BHE 1.0 1783.98429972 242256.597056 0.15 4.11733095478\n",
      "AS31 BHN 1.0 1783.98429972 264182.94683 0.15 4.15496012254\n",
      "BBOO BHE 1.0 906.706189958 59693.9696064 1.35 2.63262408262\n",
      "BBOO BHN 1.0 906.706189958 54250.8496176 1.4 2.59110016651\n",
      "BSI BHE -1,-1,-1\n",
      "BSI BHN -1,-1,-1\n",
      "CMSA BHE 1.0 584.508186863 144496.360753 0.6 2.5838358139\n",
      "CMSA BHN 1.0 584.508186863 136481.688662 0.35 2.559053292\n",
      "CNB BHE 1.0 445.42706752 358697.952212 0.4 2.74407443451\n",
      "CNB BHN 1.0 445.42706752 339993.181841 0.6 2.72081574506\n",
      "CTA BHE 1.0 1852.27415897 31192796611.2 0.5 9.28653015994\n",
      "CTA BHN 1.0 1852.27415897 143184725.559 1.95 6.94837253791\n",
      "HTT BHE 1.0 645.954161783 153864.418433 4.9 2.70308326754\n",
      "HTT BHN 1.0 645.954161783 138436.410344 4.4 2.65719539739\n",
      "LHI BHE 1.0 1440.17502318 699228.541465 1.5 4.26399187812\n",
      "LHI BHN 1.0 1440.17502318 635942.63981 1.25 4.22279067619\n",
      "MOO BHE 1.0 666.023708931 129340.978023 1.65 2.65652536421\n",
      "MOO BHN 1.0 666.023708931 128204.599383 1.75 2.65269282955\n",
      "QIS BHE 1.0 1862.61992662 758435.952696 1.9 4.68132635967\n",
      "QIS BHN 1.0 1862.61992662 765241.828476 1.9 4.68520614842\n",
      "QLP BHE 1.0 1128.07655935 741209.448183 1.9 3.97551674474\n",
      "QLP BHN 1.0 1128.07655935 147376.187383 1.75 3.27400311526\n",
      "RIV SHE 1.0 666.926648766 403893.677571 2.3 3.15234132703\n",
      "RIV SHN 1.0 666.926648766 486003.602908 3.1 3.23271376096\n",
      "RMQ SHE 1.0 1199.09535432 285851.050105 2.8 3.63630622218\n",
      "RMQ SHN 1.0 1199.09535432 253488.159795 3.2 3.58412410883\n",
      "TOO BHE 1.0 112.803990057 5604250.25401 0.15 2.95567449326\n",
      "TOO BHN 1.0 112.803990057 6502182.59022 0.25 3.020216134\n",
      "WB2 BHE 1.0 2119.67658762 31204948453.1 0.5 9.51224686065\n",
      "WB2 BHN 1.0 2119.67658762 31205844846.1 0.5 9.51225933601\n",
      "YNG BHE 1.0 428.321889438 66283.0481769 3.1 1.97855167273\n",
      "YNG BHN 1.0 428.321889438 53558.4080053 2.2 1.88597685986\n"
     ]
    }
   ],
   "source": [
    "# file to store outputs\n",
    "event_num = 0\n",
    "with open(\"../../eq.txt\",'r') as cat:\n",
    "    for line in cat:\n",
    "        \n",
    "        eq=line.split(',')\n",
    "        yr=int(eq[4])\n",
    "        mon=int(eq[5])\n",
    "        day=int(eq[6])\n",
    "        hr=int(eq[7])\n",
    "        mn=int(eq[8])\n",
    "        sec=float(eq[9])\n",
    "        code=eq[10]\n",
    "        corr=float(eq[11])\n",
    "        lon=float(eq[12])\n",
    "        lat=-1*float(eq[13]) #Latitudes in Gary Gibson catalogue given in southern hemisphere coordindates\n",
    "        dep=float(eq[14])\n",
    "        mag_type = eq[16]\n",
    "        mag_pref = float(eq[17])\n",
    "        mag_source = eq[31].split(' ')[-1]\n",
    "\n",
    "        start_time=utcdatetime.UTCDateTime(yr,mon,day,hr,mn,int(sec),int((sec-int(sec))*100000))\n",
    "#        ''' correct the time if not UTC '''\n",
    "# Is this really needed??? Looks like may already be converted??\n",
    "#        if code==\"AEST\" :\n",
    "#            start_time-=36000\n",
    "#        if code==\"WITA\" or code==\"AWST\":\n",
    "#            start_time-=28800\n",
    "        \n",
    "        # Build event object\n",
    "        event = Event(resource_id='GG_cat_' + str(event_num), creation_info='JG')\n",
    "        event_num += 1\n",
    "        origin = Origin()\n",
    "        origin.time = start_time\n",
    "        origin.longitude = lon\n",
    "        origin.latitude = lat\n",
    "        origin.depth = dep\n",
    "        event.origins.append(origin)\n",
    "        mag = Magnitude(creation_info='GG_cat')\n",
    "        mag.mag = mag_pref\n",
    "        mag.magnitude_type = mag_type\n",
    "        event.magnitudes.append(mag)\n",
    "        \n",
    "\n",
    "        ''' the time window to request the data will be 20 minutes, check maximum travel time and increase this value accordingly '''\n",
    "        end_time=start_time+960 # 16 minutes\n",
    "        ''' get all waveform data available, use wildcards to reduce the data volume and speedup the process,\n",
    "        unfortunately we need to request few times for every number of characters that forms the station name '''\n",
    "        st_3 = client.get_waveforms(\"AU\", \"???\", \"\", \"[BS]?[EN]\", start_time,end_time)\n",
    "        st_4 = client.get_waveforms(\"AU\", \"????\", \"\", \"[BS]?[EN]\", start_time,end_time)\n",
    "        if len(st_4) > 0:\n",
    "            st=st_3+st_4\n",
    "        else:\n",
    "            st=st_3\n",
    "\n",
    "        # Cleanup duplicate traces returned by server\n",
    " #       st.merge(-1) #-1 method only merges overlapping or adjacent traces with same i            \n",
    "        # Now sort the streams by station and channel\n",
    "        st.sort()\n",
    "        # Cleanup duplicate traces returned by server\n",
    "        st.merge(1, fill_value=None) #1 method only merges overlapping or adjacent traces with same id\n",
    "        # Now sort the streams by station and channel\n",
    "        st.sort()\n",
    "        \n",
    "        # Filter the stream - should it be done here on by trace???\n",
    "  #      st.filter(bandpass, freqmin=0.5, freqmax=10., )\n",
    "        # PDF file to plot all traces for this event\n",
    "##        figpdf = PdfPages('test.pdf')\n",
    "\n",
    "        ''' first we will print the record of the earthquake as in catalogue '''\n",
    "        print line\n",
    "        \n",
    "        counter = 0 # For debugging only\n",
    "        for tr in st:\n",
    "            counter +=1\n",
    "            ''' get station ID'''\n",
    "            seedid=tr.get_id()            \n",
    "            # Filter to only get stations within 20 degrees\n",
    "            try:\n",
    "                ''' get station coordinates from dataless seed '''\n",
    "                tr.stats.coordinates = parser.getCoordinates(seedid,start_time)\n",
    "                tr.stats.distance = gps2DistDegree(tr.stats.coordinates.latitude,tr.stats.coordinates.longitude,lat,lon)            \n",
    "            except (SEEDParserException,AssertionError):\n",
    "                print  tr.stats['station'],tr.stats['channel'],'-1,-1,-1'\n",
    "                continue\n",
    "            if tr.stats.distance > 20: # only use stations within 20 degrees\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "\n",
    "#            numobs = tr.count()\n",
    "#            print 'count', numobs\n",
    "#            print 'seedid', seedid\n",
    "#            print 'sample rate', tr.stats.sampling_rate\n",
    "            sample_rate = tr.stats.sampling_rate\n",
    "            # Filter the trace\n",
    "            tr.filter('bandpass', freqmin=0.5, freqmax=10., corners=6)#, df=sample_rate)\n",
    "            # Demean\n",
    "            tr.detrend('demean')\n",
    "            try:\n",
    "                tr.stats.great_circle_distance, azf, azb = \\\n",
    "                    gps2DistAzimuth(tr.stats.coordinates.latitude,tr.stats.coordinates.longitude,lat,lon)\n",
    "                travel_times=vel_model.get_travel_times(dep, tr.stats.distance)#,model=\"iasp91\")\n",
    "                #print travel_times, type(travel_times)\n",
    "                try:\n",
    "                    #for arrival in travel_times:\n",
    "                    #    print arrival.phase.name\n",
    "                   arrivals= (item for item in travel_times if item.phase.name=='S' or item.phase.name=='Sn').next()\n",
    "                except StopIteration:\n",
    "                   print \"WARNING: reference station \",tr.stats['station'],\" does not have S or Sn phases\"\n",
    "#                print arrivals\n",
    "#                for key, value in arrivals.iteritems():\n",
    "#                        print key, value\n",
    "##                S_time = start_time + arrivals['time']\n",
    "##                figure = tr.plot(handle=True)\n",
    "                # Add S arrival time\n",
    "##                pyplot.scatter([S_time],[0], marker = 'o', s=40, c='r')\n",
    "##                try:\n",
    "##                   figpdf.savefig(figure)\n",
    "##                    figure.close()\n",
    "##               except:\n",
    "##                    pass\n",
    "               # figpdf.close()\n",
    "#                  print travel_times\n",
    "                ''' lets select 20 seconds window from S-wave p2p measurements '''\n",
    "#               print start_time+arrivals['time'],start_time+arrivals['time']+20,end_time\n",
    " #               wave=tr.slice(start_time+arrivals['time'],start_time+arrivals['time']+20)\n",
    " #               if len(wave.data)>0:\n",
    " #                  amplitude,period,delay=max_p2t(wave.data,wave.stats.delta)\n",
    " #               else:\n",
    " #                   amplitude,period,delay = None,None,None\n",
    " #               if amplitude > 0. and period > 0. :\n",
    "                paz=parser.get_paz(seedid,start_time)\n",
    "                ''' calib is already applied therefore we set sensitivity to 1 '''\n",
    "                paz['sensitivity']=1.\n",
    "                # Define Wood Anderson paz based on Uhrhammer 1990 sensitivity of 2080\n",
    "                # rather than theoretical 2800 as used by obpy\n",
    "                # wa_amp=inv.estimateWoodAndersonAmplitude(paz,amplitude,period)\n",
    "                paz_wa = {'sensitivity': 2080, 'zeros': [0j], 'gain': 1,\n",
    "                          'poles': [-6.2832 - 4.7124j, -6.2832 + 4.7124j]}\n",
    "                # Now convert to WA spectra\n",
    "                wa_tr = tr.simulate(paz_remove=paz, paz_simulate=paz_wa)\n",
    "                # Plot WA record\n",
    "##                figure = wa_tr.plot(handle=True)\n",
    "##                try:\n",
    "##                    figpdf.savefig(figure)\n",
    "##                    figure.close()\n",
    "##                except:\n",
    "##                    pass\n",
    "                # Calculate WA amplitudes and periods\n",
    "#                wave=wa_tr.slice(start_time+arrivals['time'],start_time+arrivals['time']+20)\n",
    "#                print len(wave.data)\n",
    "                if len(wa_tr.data)>0:\n",
    "                    wa_amp,period,delay=max_p2t(wa_tr.data,wa_tr.stats.delta)\n",
    "                    local_mag = local_magnitude.calculate_local_magnitude(wa_amp/10e6, \\\n",
    "                                                                          [lon,lat,dep],\\\n",
    "                                                                          tr.stats.great_circle_distance/1000.)\n",
    "                                        \n",
    "                else:\n",
    "                    wa_amp,period,delay = None,None,None\n",
    "                    local_mag = None\n",
    "                ''' now we print every station-component measurement '''\n",
    "                #local_magnitude.calculate_local_magnitude\n",
    "                \n",
    "                print tr.stats['station'],tr.stats['channel'],tr.stats['calib'], \\\n",
    "                    tr.stats.great_circle_distance/1000, wa_amp,period, local_mag\n",
    "                #else:\n",
    "                #    print tr.stats['station'],tr.stats['channel'],tr.stats['calib'],amplitude,period\n",
    "            except (SEEDParserException,AssertionError):\n",
    "                print  tr.stats['station'],tr.stats['channel'],'-1,-1,-1'\n",
    "##            if counter > 10:\n",
    "##                break\n",
    "##    figpdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
